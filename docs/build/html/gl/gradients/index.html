<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>Chris Rordens Neuropsychology Lab :: MRIcroGL Gradients</title>
  

  <link rel="icon" type="image/png" sizes="32x32" href="../../_static/img/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../_static/img/favicon-16x16.png">
        <link rel="index" title="Index"
              href="../../genindex.html"/>

  <link rel="stylesheet" href="../../_static/css/insegel.css"/>

  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
        URL_ROOT:'',
        VERSION:'0.1',
        LANGUAGE:'None',
        COLLAPSE_INDEX:false,
        FILE_SUFFIX:'.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
    };
  </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script>

</head>

<body>
  <div id="insegel-container">
    <header>
      <div id="logo-container">
          
          <a href="../../index.html"><img src="../../_static/img/logo.svg"></a>
          

      </div>
      <div id="project-container">
        <h1>Chris Rordens Neuropsychology Lab Documentation</h1>
      </div>
    </header>

    <div id="content-container">

      <div id="main-content-container">
        <div id="main-content-header">
          <h1>MRIcroGL Gradients</h1>
        </div>
        <div id="main-content">
          
  <div class="section" id="mricrogl-gradients">
<h1>MRIcroGL Gradients<a class="headerlink" href="#mricrogl-gradients" title="Permalink to this headline">¶</a></h1>
<a class="reference internal image-reference" href="../../_images/gradients_2.png"><img alt="../../_images/gradients_2.png" class="align-center" src="../../_images/gradients_2.png" style="width: 130px;" /></a>
<p>Volumes appear more three dimensional if we make the top surfaces appear brighter than the bottom surface, emulating natural lighting. To do this we need to estimate the intensity gradients for our image. The <a class="reference external" href="http://www.mccauslandcenter.sc.edu/mricrogl/shaders">shaders page</a> describes how gradients are used to create lighting cues, while this page describes optimized methods for calculating gradients.</p>
<div class="section" id="details">
<h2>Details<a class="headerlink" href="#details" title="Permalink to this headline">¶</a></h2>
<p>I like to visualize gradients by thinking of two bottles of salad dressing (illustrated on the right). One bottle has been allowed to settle for a long time, so there is a clear boundary between the oil and the denser vinegar. The other bottle was shaken recently, so while the oil is more concentrated at the top and the vinegar is more concentrated at the bottom, there is a gradual change of concentration between these two extremes. The gradients simply refer to the direction and rate of change of the concentrations. Both bottles have the same gradient direction: due to gravity the top has more oil than the bottom, we can think of this direction as an arrow (in 3D this is a vector with X,Y,Z components). However the two bottles have very different gradient magnitudes (the rate of change in concentration): most of the still bottle has very low gradient magnitudes with a disk of very strong gradients at the interface between the oil and vinegar. On the other hand, the perturbed bottle has weak gradients over a large region (as the concentration differs gradually over a large region).</p>
<p>Accurate gradient estimation is typically the most computationally intensive step for volume rendering. Therefore, it is important to consider how this stage can be accelerated to ensure interactive rendering.</p>
<blockquote>
<div><ul class="simple">
<li><p>There are two basic options: one can either pre-compute the gradients prior to rendering or you can calculate the gradients during the rendering.</p></li>
</ul>
</div></blockquote>
<p>The benefit for pre-computing the gradients is that we can use slow but precise algorithms for estimating the gradients (using both smoothing and Sobel filters). However, there are disadvantages for pre-computed gradients (section 9.4 of <a class="reference external" href="http://www.real-time-volume-graphics.org/">Engel et al., 2006</a> ). First, this typically requires twice the amount of memory on your video card (as we will have a volume for the image brightness and another that codes the gradient vectors and amplitudes). Second, the gradients to reduce memory demands the gradients are stored in low precision (typically 8-bits for each the X,Y,Z vector and the amplitude) which can lead to artifacts. Finally, the precomputed gradients are stored on a regular grid but we will be often sampling at locations locations between the grid centers (causing interpolation artifacts).</p>
<dl class="simple">
<dt>The downside with generating the gradients on the fly is that this can be slow, making interactive graphics difficult. As noted by <a class="reference external" href="http://www.real-time-volume-graphics.org/">Engel et al. (2006)</a> a classic Sobel filter requires 26 texture fetches, whereas the less accurate central tendency filter requires just six prefetches. Is there any way we can get the quality of the Sobel operator in a timely manner?</dt><dd><ul class="simple">
<li><p>One option is to recognize that the <a class="reference external" href="http://en.wikipedia.org/wiki/Sobel_operator">Sobel operator</a> is separable into a smoothing filter and a central tendency filter. Likewise, the resulting 3D components are separable and can often be processed one dimension at a time. <a class="reference external" href="https://developer.apple.com/library/mac/documentation/Performance/Conceptual/OpenCL_MacProgGuide/TuningPerformanceOntheGPU/TuningPerformanceOntheGPU.html#//apple_ref/doc/uid/TP40008312-CH22-SW4">Apple</a> provides an excellent example for how this approach can be optimized. Unfortunately, this separability is not suitable for generating gradients on the fly (as the fragment shader must work in a single pass). Therefore, these tricks can only be used for pre-computed gradients (where speed is usually not crucial, and where they are still unlikely to outperform the GPU-based techniques described next).</p></li>
</ul>
</dd>
</dl>
<p>A second approach to accelerating the Sobel operator is to take advantage of the fact that our graphics card computes trilinear interpolation in hardware. Therefore, if we sample a location that is not precisely on our grid we will get a weighted average for all 8 neighboring voxels. Since this is done in hardware, it is exceptionally fast (indeed, for our volume rendering will rarely precisely sample the grid, so even the central tendency filter relies on the efficiency of this trilinear sampling). Therefore, while the classic Sobel operator requires us to get the weighted average of 26 voxel locations (requiring both texture perfecting and multiplication to apply the weighting coefficients). This allows us to mimic a Sobel filter with just 8 texture reads. <a class="reference external" href="http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter20.html">Sigg and Hadwiger</a> are the definitive description of this approach for hardware accelerated convolution, including gradient estimation (section 20.4). For the Sobel operator, we merely need to read the eight image points that are directly between the target voxel and the neighbors that share a corner. In other word, we sample each permutation of (X+/-0.5, Y+/-0.5, Z+/-0.5). To see why this works, consider the voxel directly above our target voxel (the voxel that shares a face with our target): it is 0.7 voxels away from all four top corners, whereas the four top voxels that share an edge are 0.7 voxels away from two of the corners. Finally, the four top voxels that share a corner with our target are 0.7 voxels away from the one of the corners. This perfectly matches the weighting required by the Sobel operator: so we not only reduce the number of texture fetches but also the scaling coefficients.</p>
<a class="reference internal image-reference" href="../../_images/sobel1024_0.png"><img alt="../../_images/sobel1024_0.png" class="align-center" src="../../_images/sobel1024_0.png" style="width: 100%;" /></a>
<p>You can see that the pre-computed gradients look really nice – these benefit from a careful smoothing algorithm. You can also see that the central tendency edges look pretty hard relative to the conventional Sobel (Sobel26) and our interpolated Sobel (Sobel8). In terms of frame rate (using a very large volume and my laptops’ integrated Intel GPU), I observed that the pre-computed refreshed at 29.2fps (2 texture fetches), central difference 28.3fps (7), sobel8 28.0fps (9), classic sobel26 19.5fps (27).</p>
<p>If you look carefully you will see that the Sobel8 actually seems to look better than the traditional Sobel26. How can this be? By default I have set this filter to sample a bit further away from the target. You can see the influence of sampling distance by adjusting the “sampleDistance” slider. Note that to mimic a traditional Sobel26 you would sample 0.5 voxels in each dimension from the voxel center, whereas by default I am sampling 1.0 voxel away (in theory precisely at the location of the corner voxels, but remember that our sampling is not constrained to the grid). You can try adjusting the sampling distance for each of the filters to see the effect. My default setting emulates a Sobel with a slightly larger kernel (at 0.5 the center voxels are sampled by both the top and bottom points, canceling each other out, with a larger separation we are getting unique information from more distant voxels). Obviously, large values will lead to smoothing that can miss details, but also attenuates high frequency noisy. A value of about 1.0 seems about right, and note that even with larger sampling distances the Central Distance operator does not look as good as the Sobel8.</p>
<p>All of these shaders use one extra trick: they <a class="reference external" href="http://marcusbannerman.co.uk/index.php/home/42-articles/97-vol-render-optimizations.html">reuse gradient normals</a> . You can see the influence by checking the reuseGradients check box. The basic idea here is that our estimates of gradient vector directions can be noisy. Therefore, if our current gradient magnitude is lower than our previous estimate we will use the vectors from the prior estimate. Notice that this trick especially helps the pre-computed gradients, directly addressing the criticism of pre-computed gradients described by <a class="reference external" href="http://www.real-time-volume-graphics.org/">Engel (e.g. their Figure 9.17)</a>.</p>
<p>Since the GLSL shaders are simply text files, you can edit them to try new effects. For example I also include Sobel14 which essentially combines the Sobel8 and Central Difference (sampling a sphere of locations both aligned to the faces and corners of the target voxel). I also include an even faster version of the central difference that <a class="reference external" href="http://prideout.net/blog/?tag=volume-rendering">compares just three locations</a> to sampled target voxel, note that this introduces a slight spatial bias but it is exceptionally fast.</p>
</div>
<div class="section" id="links">
<h2>Links<a class="headerlink" href="#links" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="http://www.real-time-volume-graphics.org/">Engel et al.’s</a> book Real-Time Volume Graphics remains an outstanding introduction to the topic. If you prefer electronic content, visit their <a class="reference external" href="http://www.real-time-volume-graphics.org/?page_id=28">tutorial</a> page, with Part 9 relevant to gradient estimation.</p></li>
<li><p><a class="reference external" href="http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter20.html">Sigg and Hadwiger’s</a> chapter in the book GPU Gems 2 is the seminal reference for the techniques discussed here.</p></li>
<li><p>Numerous web pages describe how to optimize the common Gaussian blur filter for the GPU. These are useful if you wish to precompute yourgradients by separating the Sobel operator into a blur stepfollowed by central tendency. Some of the best pages are from <a class="reference external" href="http://www.realtimerendering.com/blog/quick-gaussian-filtering/">Eric</a>, <a class="reference external" href="http://www.sunsetlakesoftware.com/2013/10/21/optimizing-gaussian-blurs-mobile-gpu">Brad</a> , and <a class="reference external" href="http://rastergrid.com/blog/2010/09/efficient-gaussian-blur-with-linear-sampling/">Daniel</a>. Alternatives are provided by <a class="reference external" href="http://fgiesen.wordpress.com/2012/08/01/fast-blurs-2/">Fabian</a> (useful for CPUs where you do not have hardware accelerated interpolation) and the approximation from <a class="reference external" href="https://developer.apple.com/library/mac/documentation/Performance/Conceptual/OpenCL_MacProgGuide/TuningPerformanceOntheGPU/TuningPerformanceOntheGPU.html#//apple_ref/doc/uid/TP40008312-CH22-SW4">Apple Computers</a> .</p></li>
<li><p><a class="reference external" href="http://www.mate.tue.nl/mate/pdfs/10318.pdf">Ruijters et al. (2009)</a> further refine Sigg and Hadwiger’s algorithm removing the need to pre-compute lookup tables.</p></li>
</ul>
</div></blockquote>
<a class="reference internal image-reference" href="../../_images/inia320.jpg"><img alt="../../_images/inia320.jpg" class="align-center" src="../../_images/inia320.jpg" style="width: 320px;" /></a>
</div>
</div>


        </div>
      </div>

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
            <input type="text" name="q" placeholder="Search..." />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">

          
  
    
  
  
    <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../asl/index.html">Arterial Spin Labeling (ASL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blindside/index.html">Blindside</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bmp_contrast/index.html">Bitmap Contrast</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CenterOfCancellation/index.html">Center of Cancellation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../directions/index.html">Directions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../diyFmri/index.html">DIY fMRI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dti/index.html">DTI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../elecro/index.html">ELEcro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../EMGRecorder/index.html">EMG Recorder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fieldmaps/index.html">Fieldmaps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fmriSimulator/index.html">fMRI Simulator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jpeg-formats/index.html">JPEG Format Variations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mriconcepts/index.html">MRI Contrast</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mricro/index.html">MRIcro for macOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">MRIcroGL Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extract/index.html">MRIcroGL Object Extraction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MRIcroGL Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../shaders/index.html">MRIcroGL Shaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../open-source-eegecgemg/index.html">DIY Electrophysiology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimizingspmfsl/index.html">Optimizing FSL and SPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../oscilloscope/index.html">Oscilloscope using Teensy or Arduino</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../part/index.html">Physiological Artifact Removal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../psyc450/index.html">Sensation and Perception (PSYC450)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../psyc589888/index.html">Image to Inference (PSYC589/888)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pwi/index.html">Perfusion-weighted imaging (PWI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../qa/index.html">Quality Assurance (QA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spatial/index.html">Spatial Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spm8-scripts/index.html">spmScripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stc/index.html">Slice Time Correction (STC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stimsync/index.html">StimSync</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stimsync-api/index.html">StimSync API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../temporal/index.html">Temporal Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../publications/index.html">Publications</a></li>
</ul>

  


        </div>

        

      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            
                <li class="footer-element">
                    
                        <a href="../../_sources/gl/gradients/index.rst.txt" rel="nofollow"> source</a>
                    
                </li>
            

            

            
        </ul>
        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/Autophagy/insegel">Insegel</a>

        </div>
    </div>

    <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

    <script type="text/javascript">
      $("#menu-toggle").click(function() {
        $("#menu-toggle").toggleClass("toggled");
        $("#side-menu-container").slideToggle(300);
      });
    </script>

</footer> 

</div>

</body>
</html>